# run_predictions.py (ìµœì¢… ìˆ˜ì •ë³¸)

import os
import json
from datetime import date, timedelta
import requests
import pandas as pd
import numpy as np
import yfinance as yf
from statsmodels.tsa.arima.model import ARIMA
from tenacity import retry, stop_after_attempt, wait_fixed
from ai_analyzer import analyze_article_with_ai, generate_trend_summary_with_ai

# --- API ë° ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ ---

@retry(stop=stop_after_attempt(3), wait=wait_fixed(5))
def get_marketaux_news(api_key):
    """Marketaux APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not api_key: return []
    url = f"https://api.marketaux.com/v1/news/all?countries=us&filter_entities=true&language=en&limit=10&api_token={api_key}"
    try:
        response = requests.get(url, timeout=20)
        response.raise_for_status()
        print("âœ… Marketaux ë‰´ìŠ¤ ìˆ˜ì§‘ ì„±ê³µ")
        return response.json().get('data', [])
    except requests.exceptions.RequestException as e:
        print(f"âŒ Marketaux API ì˜¤ë¥˜: {e}")
        return []

@retry(stop=stop_after_attempt(3), wait=wait_fixed(5))
def get_fx_rate(api_key):
    """ExchangeRate-APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì‹  USD/KRW í™˜ìœ¨ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not api_key: return 1422.0
    url = f"https://v6.exchangerate-api.com/v6/{api_key}/latest/USD"
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        krw_rate = response.json().get('conversion_rates', {}).get('KRW')
        if krw_rate:
            print("âœ… ìµœì‹  í™˜ìœ¨ ì •ë³´ ìˆ˜ì§‘ ì„±ê³µ")
            return krw_rate
    except requests.exceptions.RequestException as e:
        print(f"âŒ ExchangeRate-API ì˜¤ë¥˜: {e}")
    return 1422.0

# --- ì°¨íŠ¸ ë°ì´í„° ìƒì„± í•¨ìˆ˜ ---

def get_yfinance_chart_data(ticker, days=30, forecast_days=7):
    """yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ ê³¼ê±° ë° ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
    print(f"--- ğŸ“ˆ '{ticker}' ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘ ---")
    try:
        today = date.today()
        start_date = today - timedelta(days=days + 60)
        
        data = yf.download(ticker, start=start_date, end=today, progress=False, timeout=30)

        if data is None or data.empty:
            print(f"âŒ '{ticker}' ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨. APIë¡œë¶€í„° ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None
        
        hist_data = data['Close'].dropna().astype(float).sort_index().tail(days)

        if len(hist_data) < 20:
            print(f"âš ï¸ '{ticker}' ë°ì´í„°ê°€ 20ì¼ ë¯¸ë§Œ({len(hist_data)}ì¼)ì´ì–´ì„œ ì˜ˆì¸¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
            
        model = ARIMA(hist_data, order=(5,1,0)).fit()
        forecast = model.forecast(steps=forecast_days)
        
        hist_labels = [d.strftime('%m-%d') for d in hist_data.index]
        forecast_labels = [(today + timedelta(days=i)).strftime('%m-%d') for i in range(1, forecast_days + 1)]
        
        print(f"âœ… '{ticker}' ê·¸ë˜í”„ ì˜ˆì¸¡ ì™„ë£Œ.")
        return {
            "labels": hist_labels + forecast_labels,
            # âœ¨ ì¤‘ìš”: .tolist()ë¥¼ ì‚¬ìš©í•˜ì—¬ [ [1], [2] ]ê°€ ì•„ë‹Œ [ 1, 2 ] í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ë§Œë“­ë‹ˆë‹¤.
            "historical": np.round(hist_data.values, 2).tolist(),
            "forecast": [None] * len(hist_data) + np.round(forecast.values, 2).tolist()
        }
    except Exception as e:
        print(f"âŒ '{ticker}' ì°¨íŠ¸ ë°ì´í„° ìƒì„± ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def get_fx_chart_data(latest_rate, days=30, forecast_days=7):
    """í™˜ìœ¨ ì°¨íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        today = date.today()
        start_date = today - timedelta(days=days)
        
        np.random.seed(42)
        price_changes = np.random.randn(days) * 0.5
        simulated_past = latest_rate + np.cumsum(price_changes[::-1])
        
        hist_data = pd.Series(simulated_past, index=pd.to_datetime([start_date + timedelta(days=i) for i in range(days)]))
        model = ARIMA(hist_data, order=(5,1,0)).fit()
        forecast = model.forecast(steps=forecast_days)

        hist_labels = [d.strftime('%m-%d') for d in hist_data.index]
        forecast_labels = [(today + timedelta(days=i)).strftime('%m-%d') for i in range(1, forecast_days + 1)]

        return {
            "labels": hist_labels + forecast_labels,
            "historical": np.round(hist_data.values, 2).tolist(),
            "forecast": [None] * len(hist_data) + np.round(forecast.values, 2).tolist()
        }
    except Exception as e:
        print(f"âŒ í™˜ìœ¨ ì°¨íŠ¸ ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---

if __name__ == "__main__":
    if not os.path.exists('data'):
        os.makedirs('data')

    print("--- ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ë° AI ë¶„ì„ ì‹œì‘ ---")
    marketaux_key = os.getenv("MARKETAUX_API_KEY")
    articles = get_marketaux_news(marketaux_key)
    
    processed_articles, all_keywords, total_sentiment = [], [], 0.0
    if articles:
        for article in articles:
            content = article.get('description') or article.get('snippet', '')
            if content and len(content) > 100:
                ai_result = analyze_article_with_ai(content)
                article.update(ai_result)
                article['image_url'] = article.get('image_url', 'https://via.placeholder.com/400x220.png?text=No+Image')
                processed_articles.append(article)
                total_sentiment += ai_result.get('sentiment', 0.0)
                if ai_result.get('keywords'):
                    all_keywords.extend(ai_result['keywords'])
    
    market_sentiment_score = total_sentiment / len(processed_articles) if processed_articles else 0.0
    trend_summary = generate_trend_summary_with_ai(all_keywords, market_sentiment_score)
    print("âœ… ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ.")
    
    nasdaq_data = get_yfinance_chart_data('^IXIC')
    kospi_data = get_yfinance_chart_data('^KS11')
    
    fx_api_key = os.getenv("EXCHANGERATE_API_KEY")
    latest_fx_rate = get_fx_rate(fx_api_key)
    fx_data = get_fx_chart_data(latest_fx_rate)
    
    final_data = {
        "articles": processed_articles,
        "trend_summary": trend_summary,
        "market_sentiment_score": round(market_sentiment_score, 3),
        "nasdaq_data": nasdaq_data,
        "kospi_data": kospi_data,
        "fx_data": fx_data,
        "last_updated": date.today().strftime("%Y-%m-%d %H:%M:%S")
    }

    with open('data/daily_data.json', 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=4)
    
    print("\nğŸš€ ëª¨ë“  ë°ì´í„°ê°€ 'data/daily_data.json'ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")