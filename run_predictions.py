# run_predictions.py (ì°¨íŠ¸ ê¸°ê°„ 90ì¼ë¡œ í™•ì¥)

import os
import json
from datetime import date, timedelta
import requests
import pandas as pd
import numpy as np
import yfinance as yf
from statsmodels.tsa.arima.model import ARIMA
from tenacity import retry, stop_after_attempt, wait_fixed
from dotenv import load_dotenv
from ai_analyzer import analyze_article_with_ai, generate_trend_summary_with_ai

load_dotenv()

@retry(stop=stop_after_attempt(3), wait=wait_fixed(5))
def get_marketaux_news(api_key):
    if not api_key: return []
    url = f"https://api.marketaux.com/v1/news/all?countries=us&filter_entities=true&language=en&limit=10&api_token={api_key}"
    try:
        response = requests.get(url, timeout=20)
        response.raise_for_status()
        print("âœ… Marketaux ë‰´ìŠ¤ ìˆ˜ì§‘ ì„±ê³µ")
        return response.json().get('data', [])
    except requests.exceptions.RequestException as e:
        print(f"âŒ Marketaux API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise e

@retry(stop=stop_after_attempt(3), wait=wait_fixed(5))
def get_yfinance_chart_data(ticker, days=90, forecast_days=7): # âœ¨ ê¸°ë³¸ ì¡°íšŒ ê¸°ê°„ì„ 90ì¼ë¡œ ë³€ê²½
    """yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ ê³¼ê±° ë° ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print(f"--- ğŸ“ˆ '{ticker}' ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘ ---")
    try:
        today = date.today()
        # ë°ì´í„°ë¥¼ ë„‰ë„‰í•˜ê²Œ ê°€ì ¸ì˜´
        start_date = today - timedelta(days=days + 60)
        
        data = yf.download(ticker, start=start_date, end=today, progress=False, timeout=30)
        if data is None or data.empty:
            print(f"âŒ '{ticker}' ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨.")
            return None
        
        # ìµœê·¼ 90ì¼ ë°ì´í„°ë§Œ ì„ íƒí•˜ì—¬ ì°¨íŠ¸ì— í‘œì‹œ
        hist_data = data['Close'].dropna().astype(float).sort_index().tail(days)

        if len(hist_data) < 20:
            print(f"âš ï¸ '{ticker}' ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì˜ˆì¸¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
            
        model = ARIMA(hist_data, order=(5,1,0)).fit()
        forecast = model.forecast(steps=forecast_days)
        
        hist_labels = [d.strftime('%m-%d') for d in hist_data.index]
        forecast_labels = [(today + timedelta(days=i)).strftime('%m-%d') for i in range(1, forecast_days + 1)]
        
        print(f"âœ… '{ticker}' ê·¸ë˜í”„ ì˜ˆì¸¡ ì™„ë£Œ.")
        return {
            "labels": hist_labels + forecast_labels,
            "historical": np.round(hist_data.values, 2).tolist(),
            "forecast": [None] * len(hist_data) + np.round(forecast.values, 2).tolist()
            # ì´ë™í‰ê· ì„  ë°ì´í„° ì œê±°
        }
    except Exception as e:
        print(f"âŒ '{ticker}' ì°¨íŠ¸ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

if __name__ == "__main__":
    if not os.path.exists('data'): os.makedirs('data')

    print("--- ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ë° AI ë¶„ì„ ì‹œì‘ ---")
    marketaux_key = os.getenv("MARKETAUX_API_KEY")
    articles = []
    try:
        articles = get_marketaux_news(marketaux_key)
    except Exception:
        print("ìµœì¢…ì ìœ¼ë¡œ Marketaux ë‰´ìŠ¤ ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    print(f"â¡ï¸ ì´ {len(articles)}ê°œì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
    if not articles:
        print("âš ï¸  ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ì–´ AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    processed_articles, all_keywords, total_sentiment = [], [], 0.0
    if articles:
        for i, article in enumerate(articles):
            print(f"â¡ï¸  ê¸°ì‚¬ {i+1}/{len(articles)} ë¶„ì„ ì¤‘...")
            content = article.get('description') or article.get('snippet', '')
            if content and len(content) > 100:
                ai_result = analyze_article_with_ai(content)
                article.update(ai_result)
                processed_articles.append(article)
                total_sentiment += ai_result.get('sentiment', 0.0)
                if ai_result.get('keywords'): all_keywords.extend(ai_result['keywords'])
    
    market_sentiment_score = total_sentiment / len(processed_articles) if processed_articles else 0.0
    trend_summary = generate_trend_summary_with_ai(all_keywords, market_sentiment_score)
    print("âœ… ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ.")
    
    # 90ì¼ ê¸°ê°„ìœ¼ë¡œ ë°ì´í„° ì¡°íšŒ
    nasdaq_data = get_yfinance_chart_data('^IXIC', days=90)
    kospi_data = get_yfinance_chart_data('^KS11', days=90)
    fx_data = get_yfinance_chart_data('USDKRW=X', days=90)
    
    final_data = {"articles": processed_articles, "trend_summary": trend_summary, "market_sentiment_score": round(market_sentiment_score, 3), "nasdaq_data": nasdaq_data, "kospi_data": kospi_data, "fx_data": fx_data, "last_updated": date.today().strftime("%Y-%m-%d %H:%M:%S")}

    with open('data/daily_data.json', 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=4)
    
    print("\nğŸš€ ëª¨ë“  ë°ì´í„°ê°€ 'data/daily_data.json'ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")